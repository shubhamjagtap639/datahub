name: metadata ingestion
on:
  push:
    branches:
      - master
    paths:
      - "metadata-ingestion/**"
      - "metadata-models/**"
  pull_request:
    branches:
      - master
    paths:
      - "metadata-ingestion/**"
      - "metadata-models/**"
  release:
    types: [published, edited]

concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: true

jobs:
  metadata-ingestion-general:
    runs-on: ubuntu-latest
    env:
      SPARK_VERSION: 3.0.3
      DATAHUB_TELEMETRY_ENABLED: false
    strategy:
      matrix:
        python-version: ["3.7", "3.10.6"]
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}
      - name: Install dependencies
        run: ./metadata-ingestion/scripts/install_deps.sh
      - name: Run metadata-ingestion tests
        run: ./gradlew :metadata-ingestion:build :metadata-ingestion:testQuick :metadata-ingestion:check
      - uses: actions/upload-artifact@v3
        if: always()
        with:
          name: Test Results (metadata ingestion ${{ matrix.python-version }} testQuick)
          path: |
            **/build/reports/tests/test/**
            **/build/test-results/test/**
            **/junit.*.xml

  metadata-ingestion:
    runs-on: ubuntu-latest
    env:
      SPARK_VERSION: 3.0.3
      DATAHUB_TELEMETRY_ENABLED: false
      DATAHUB_LOOKML_GIT_TEST_SSH_KEY: ${{ secrets.DATAHUB_LOOKML_GIT_TEST_SSH_KEY }}
    strategy:
      matrix:
        python-version: ["3.7", "3.10"]
        command:
          [
            "installAirflow1",
            "testIntegration",
            "testIntegrationBatch1",
            "testSlowIntegration",
          ]
      fail-fast: false
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}
      - uses: vemonet/setup-spark@v1 # spark is required for pyspark+pydeequ data lake profiling
        with:
          spark-version: "3.0.3"
          hadoop-version: "3.2"
      - name: Install dependencies
        run: ./metadata-ingestion/scripts/install_deps.sh
      - name: Run metadata-ingestion tests
        run: ./gradlew :metadata-ingestion:build :metadata-ingestion:${{ matrix.command }} -x:metadata-ingestion:testQuick -x:metadata-ingestion:check
      - name: pip freeze show list installed
        if: always()
        run: source metadata-ingestion/venv/bin/activate && pip freeze
      - uses: actions/upload-artifact@v3
        if: always()
        with:
          name: Test Results (metadata ingestion ${{ matrix.python-version }})
          path: |
            **/build/reports/tests/test/**
            **/build/test-results/test/**
            **/junit.*.xml

  event-file:
    runs-on: ubuntu-latest
    steps:
      - name: Upload
        uses: actions/upload-artifact@v3
        with:
          name: Event File
          path: ${{ github.event_path }}
